# -----------------------------------------
# THIS FILE WAS AUTOGENERATED! DO NOT EDIT!
# -----------------------------------------
# file to edit: 10_resnet_two_sites_parallel.ipynb

from collections import OrderedDict
import json
import os
from os.path import dirname, join
from functools import reduce
from pdb import set_trace

import cv2 as cv
import jupytools
import jupytools.syspath
import numpy as np
import pandas as pd
import PIL.Image
import matplotlib.pyplot as plt

from catalyst.utils import get_one_hot
import pretrainedmodels
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from visdom import Visdom

jupytools.syspath.add(join(dirname(os.getcwd()), 'protein_project'))
jupytools.syspath.add('rxrx1-utils')
if jupytools.is_notebook():
    from tqdm import tqdm_notebook as tqdm
else:
    from tqdm import tqdm as tdqm

import contextlib, io
with contextlib.redirect_stderr(io.StringIO()):
    from basedir import ROOT, NUM_CLASSES
    from catalyst_visdom import BatchMetricsPlotCallback, EpochMetricsPlotCallback
    from dataset import load_data, build_stats_index, RxRxDataset
    from model.utils import freeze_all, unfreeze_layers
    from visual import rgb, six, show_1, show


torch.set_default_tensor_type(torch.FloatTensor)


from augmentation import JoinChannels, SwapChannels, Resize, ToFloat, Rescale
from augmentation import VerticalFlip, HorizontalFlip, PixelStatsNorm, composer
from augmentation import AugmentedImages


class RxRxImages(Dataset):
    def __init__(self, meta_df, img_dir, site=1, channels=(1, 2, 3, 4, 5, 6),
                 open_image=PIL.Image.open, n_classes=NUM_CLASSES, train=True):

        self.records = meta_df.to_records(index=False)
        self.img_dir = img_dir
        self.site = site
        self.channels = channels
        self.n = len(self.records)
        self.open_image = open_image
        self.n_classes = n_classes
        self.train = train

    def _get_image_path(self, index, channel):
        r = self.records[index]
        exp, plate, well = r.experiment, r.plate, r.well
        subdir = 'train' if self.train else 'test'
        path = f'{self.img_dir}/{subdir}/{exp}/Plate{plate}/{well}_s{self.site}_w{channel}.png'
        return path

    def __getitem__(self, index):
        paths = [self._get_image_path(index, ch) for ch in self.channels]
        img = np.stack([self.open_image(p) for p in paths])
        img = img.astype(np.float32)
        img = img.transpose(1, 2, 0)
        r = self.records[index]
        if self.train:
            sirna = r.sirna
            target = int(sirna)
            onehot = get_one_hot(target, num_classes=self.n_classes)
            return {'features': img, 'targets': target, 'targets_one_hot': onehot}
        else:
            id_code = r.id_code
            return {'features': img, 'id_code': id_code}

    def __len__(self):
        return self.n


class TwoSiteImages(Dataset):
    def __init__(self, ds1, ds2):
        assert len(ds1) == len(ds2)
        self.ds1, self.ds2 = ds1, ds2
        self.size = len(ds1)

    def __getitem__(self, index):
        return {'site1': self.ds1[index], 'site2': self.ds2[index]}

    def __len__(self):
        return self.size


from split import StratifiedSplit
splitter = StratifiedSplit()
trn_df, val_df = splitter(pd.read_csv(ROOT/'train.csv'))
tst_df = pd.read_csv(ROOT/'test.csv')


sz = 512
trn_ds = TwoSiteImages(
    ds1=AugmentedImages(ds=RxRxImages(trn_df, ROOT, site=1), tr=composer(resize=sz)),
    ds2=AugmentedImages(ds=RxRxImages(trn_df, ROOT, site=2), tr=composer(resize=sz))
)
val_ds = TwoSiteImages(
    ds1=AugmentedImages(ds=RxRxImages(val_df, ROOT, site=1), tr=composer(resize=sz)),
    ds2=AugmentedImages(ds=RxRxImages(val_df, ROOT, site=2), tr=composer(resize=sz))
)
tst_ds = TwoSiteImages(
    ds1=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=1, train=False), tr=composer(resize=sz)),
    ds2=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=2, train=False), tr=composer(resize=sz))
)


def new_loader(ds, bs, shuffle=True, num_workers=12):
    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers)


def resnet18(head_fn=None, n_classes=NUM_CLASSES):
    model_fn = pretrainedmodels.__dict__['resnet18']
    model = model_fn(num_classes=1000, pretrained='imagenet')
    feat_dim = model.last_linear.in_features
    if head_fn is None:
        model.last_linear = nn.Linear(feat_dim, n_classes)
    else:
        model.last_linear = head_fn(feat_dim)
    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)
    conv1 = model.conv1.weight
    with torch.no_grad():
        new_conv.weight[:, :] = torch.stack([torch.mean(conv1, 1)]*6, dim=1)
    model.conv1 = new_conv
    return model


class ResNet18_TwoSites(nn.Module):
    def __init__(self, n_classes=NUM_CLASSES):
        super().__init__()

        def head(in_features):
            return nn.Linear(in_features, in_features)

        self.m1 = resnet18(head_fn=head)
        self.m2 = resnet18(head_fn=head)
        self.drop = nn.Dropout(0.25)
        self.relu = nn.ReLU(inplace=True)
        self.top = nn.Linear(self.m1.last_linear.out_features * 2, n_classes)

    def forward(self, s1, s2):
        out1 = self.m1(s1)
        out2 = self.m2(s2)
        concat = torch.cat([out1, out2], dim=1)
        out = self.top(self.relu(self.drop(concat)))
        return out


def freeze_all(model):
    for name, child in model.named_children():
        print('Freezing layer:', name)
        for param in child.parameters():
            param.requires_grad = False


def unfreeze_all(model):
    for name, child in model.named_children():
        print('Un-freezing layer:', name)
        for param in child.parameters():
            param.requires_grad = True


def unfreeze(model, names):
    for name, child in model.named_children():
        if name not in names:
            continue
        print('Un-freezing layer:', name)
        for param in child.parameters():
            param.requires_grad = True


model = ResNet18_TwoSites()
freeze_all(model.m1)
freeze_all(model.m2)
freeze_all(model)


from visdom import Visdom


class RollingLoss:
    def __init__(self, smooth=0.98):
        self.smooth = smooth
        self.prev = 0
    def __call__(self, curr, batch_no):
        a = self.smooth
        avg_loss = a*self.prev + (1 - a)*curr
        debias_loss = avg_loss/(1 - a**batch_no)
        self.prev = avg_loss
        return debias_loss


def create_loaders(batch_size):
    trn_dl = new_loader(trn_ds, bs=batch_size, shuffle=True)
    val_dl = new_loader(val_ds, bs=batch_size, shuffle=False)
    return OrderedDict([('train', trn_dl), ('valid', val_dl)])


loss_fn = nn.CrossEntropyLoss()
device = torch.device('cuda:0')


epochs = 1000
patience = 500

opt = torch.optim.AdamW(model.parameters(), lr=0.0003)
sched = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.95)
model = model.to(device)
rolling_loss = dict(train=RollingLoss(), valid=RollingLoss())
steps = dict(train=0, valid=0)

trials = 0
best_metric = -np.inf
history = []
stop = False

vis = Visdom(server='0.0.0.0', port=9091,
             username=os.environ['VISDOM_USERNAME'],
             password=os.environ['VISDOM_PASSWORD'])

loaders = create_loaders(batch_size=32)

for epoch in range(1, epochs+1):
    print(f'Epoch [{epoch}/{epochs}]')

    if epoch == 1:
        unfreeze_layers(model, ['m1.last_linear', 'm2.last_linear', 'top'])
    elif epoch == 5:
        loaders = create_loaders(batch_size=16)
        unfreeze_all(model.m1)
        unfreeze_all(model.m2)
        unfreeze_all(model)

    curr_lr = opt.param_groups[0]['lr']
    vis.line(X=[epoch], Y=[curr_lr], win='lr', name='lr', update='append')
    iteration = dict(epoch=epoch, train_loss=list(), valid_loss=list())
    print(f"Current learning rate: {opt.param_groups[0]['lr']:.2E}")

    for name, loader in loaders.items():
        is_training = name == 'train'
        count = 0
        metric = 0.0

        with torch.set_grad_enabled(is_training):
            for batch in loader:
                steps[name] += 1
                opt.zero_grad()
                #x = batch['features'].to(device)
                #y = batch['targets'].to(device)
                #out = model(x)
                y = batch['site1']['targets'].to(device)

                out = model(
                    batch['site1']['features'].to(device),
                    batch['site2']['features'].to(device)
                )

                if is_training:
                    loss = loss_fn(out, y)
                    loss.backward()
                    opt.step()

                avg_loss = rolling_loss[name](loss.item(), steps[name])
                iteration[f'{name}_loss'].append(avg_loss)
                y_pred = out.softmax(dim=1).argmax(dim=1)
                acc = (y_pred == y).float().mean().item()
                metric += acc
                count += len(batch)
                vis.line(X=[steps[name]], Y=[avg_loss], name=f'{name}_loss',
                         win=f'{name}_loss', update='append',
                         opts=dict(title=f'Running Loss [{name}]'))

        metric /= count
        iteration[f'{name}_acc'] = metric
        vis.line(X=[epoch], Y=[avg_loss], name=f'{name}', win='avg_loss',
                 update='append', opts=dict(title='Average Epoch Loss'))
        vis.line(X=[epoch], Y=[metric], name=f'{name}', win='accuracy',
                 update='append', opts=dict(title=f'Accuracy'))

        last_loss = iteration[f'{name}_loss'][-1]

        print(f'{name} metrics: accuracy={metric:2.3%}, loss={last_loss:.4f}')

        if is_training:
            sched.step()

        else:
            # sched.step(metric)
            if metric > best_metric:
                trials = 0
                best_metric = metric
                print('Score improved!')
                torch.save(model.state_dict(), f'two_sites/train.{epoch}.pth')
            else:
                trials += 1
                if trials >= patience:
                    stop = True
                    break

    history.append(iteration)

    print('-' * 80)

    if stop:
        print(f'Early stopping on epoch: {epoch}')
        break

torch.save(history, 'history.pth')
