# -----------------------------------------
# THIS FILE WAS AUTOGENERATED! DO NOT EDIT!
# -----------------------------------------
# file to edit: 03_cell_type_refactor.ipynb

from collections import Counter, defaultdict, OrderedDict
from functools import partial
import json
from operator import itemgetter
import os
from pdb import set_trace

import cv2
from imageio import imread
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import PIL.Image
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tqdm import tqdm_notebook as tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from torch.utils.data import Dataset, DataLoader

import albumentations as T
from catalyst.contrib.schedulers import OneCycleLR
from catalyst.contrib.modules import GlobalConcatPool2d
from catalyst.dl import SupervisedRunner
from catalyst.dl.callbacks import AccuracyCallback
from catalyst.dl.core import Callback
from catalyst.utils import get_one_hot
import pretrainedmodels
from visdom import Visdom

from data_bunch import rio


os.environ['CUDA_VISIBLE_DEVICES'] = '1'


def list_files(folder):
    dirname = os.path.expanduser(folder)
    return [os.path.join(dirname, x) for x in os.listdir(dirname)]

def load_data(filenames=None):

    def treatment_only(records):
        return [r for r in records if r['well_type'] == 'treatment']

    def re_encode(records):
        enc = LabelEncoder()
        labels = [r['sirna'] for r in records]
        encoded = enc.fit_transform(labels)
        for enc, r in zip(encoded, records):
            r['enc_sirna'] = enc
        return enc

    if filenames is None:
        filenames = [f'{fn}.json' for fn in ('train', 'test')]

    data, encoders = [], []
    for filename in filenames:
        with open(filename) as f:
            records = treatment_only(json.load(f))
        encoder = re_encode(records)
        data.append(records)
        encoders.append(encoder)
    num_classes =  max([r['enc_sirna'] for r in data[0]]) + 1
    return {'data': data, 'encoders': encoders, 'num_classes': num_classes}

class RxRxDataset(Dataset):
    def __init__(self, items, num_classes, onehot=True, label_smoothing=None,
                 features_key='images', targets_key='enc_sirna',
                 channels_mode='six', drop_meta=True, open_fn=PIL.Image.open, tr=None):

        assert channels_mode in ('six', 'rgb')
        super().__init__()
        self.items = items
        self.onehot = onehot
        self.label_smoothing = label_smoothing
        self.features_key = features_key
        self.targets_key = targets_key
        self.channels_mode = channels_mode
        self.drop_meta = drop_meta
        self.num_classes = num_classes
        self.open_fn = open_fn
        self.tr = tr

    def __len__(self):
        return len(self.items)

    def __getitem__(self, index):
        item = self.items[index].copy()
        bunch = sorted(item.pop(self.features_key), key=itemgetter(0))
        channels = OrderedDict()
        if self.channels_mode == 'six':
            for i, filename in bunch:
                channels[f'chan_{i}'] = np.array(self.open_fn(filename))
        elif self.channels_mode == 'rgb':
            img = np.stack([self.open_fn(filename) for filename in bunch])
            img = rio.convert_tensor_to_rgb(img)
            for i in range(3):
                channes[f'chan_{i}'] = img[i,:,:]
        y = item[self.targets_key]
        if self.drop_meta:
            sample = item
            sample['features'] = channels
            sample['targets'] = y
        else:
            sample = dict(features=channels, targets=y)
        if self.onehot:
            y_enc = get_one_hot(
                y, smoothing=self.label_smoothing,
                num_classes=self.num_classes)
            sample['targets_one_hot'] = y_enc
        return sample

    def join_channels(self, x):
        return np.stack([channel for _, channel in x['features'].items()])


def augment(x, tr):
    main, *rest = list(x['features'].values())
    aug_input = dict(image=main)
    aug_input.update({f'image{i}': image for i, image in enumerate(rest)})
    augmented = tr(**aug_input)
    unpacked = [augmented['image']] + [augmented[f'image{i}'] for i in range(5)]
    sample = np.stack(unpacked)
    return sample

class Augmented(Dataset):
    def __init__(self, ds, tr):
        self.ds = ds
        self.tr = tr
    def __len__(self):
        return len(self.ds)
    def __getitem__(self, index):
        sample = self.ds[index]
        aug_img = augment(sample, self.tr)
        sample['features'] = aug_img
        return sample


class VisdomCallback(Callback):

    def __init__(self,
                 username='username', password='password',
                 host='0.0.0.0', port=9090, use_env_creds=False):
        """
        Args:
            username (str): Visdom server username.
            password (str): Visdom server password.
            host (str): Visdom server address.
            port (int): Visdom server port.
            use_env_creds (bool): If True, then ignore credentials
                passed as __init__ parameters and use Visdom
                environment variables instead.
        """

        super().__init__()

        if use_env_creds:
            username = os.environ['VISDOM_USERNAME']
            password = os.environ['VISDOM_PASSWORD']

        self.vis = Visdom(
            username=username, password=password,
            server=host, port=port)

class BatchMetricsPlotCallback(VisdomCallback):
    def on_batch_end(self, state):
        for k, v in state.metrics.batch_values.items():
            self.vis.line(X=[state.step], Y=[v], win=k, name=k,
                          update='append', opts=dict(title=k))

class EpochMetricsPlotCallback(VisdomCallback):
    def on_epoch_end(self, state):
        for k, v in state.metrics.batch_values.items():
            self.vis.line(X=[state.step], Y=[v], win=k, name=k,
                          update='append', opts=dict(title=k))


# def build_model(n_classes):
#     model = pretrainedmodels.resnet50()
#     model.avgpool = GlobalConcatPool2d()
#     model.last_linear = nn.Sequential(
#         nn.Linear(4096, 2048),
#         nn.Dropout(0.5),
#         nn.ReLU(inplace=True),
#         nn.Linear(2048, 1024),
#         nn.Dropout(0.5),
#         nn.ReLU(inplace=True),
#         nn.Linear(1024, n_classes)
#     )
#     conv1 = model.conv1
#     new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)
#     new_conv.weight.data[:,0:3,:] = conv1.weight.data.clone()
#     new_conv.weight.data[:,3:6,:] = conv1.weight.data.clone()
#     model.conv1 = new_conv
#     del conv1
#     return model

# def get_model(model_name, num_classes, pretrained='imagenet'):
#     model_fn = pretrainedmodels.__dict__[model_name]
#     model = model_fn(num_classes=1000, pretrained=pretrained)
#     dim_feats = model.last_linear.in_features
#     model.last_linear = nn.Linear(dim_feats, num_classes)
#     conv1 = model.conv1
#     new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)
#     new_conv.weight.data[:,0:3,:] = conv1.weight.data.clone()
#     new_conv.weight.data[:,3:6,:] = conv1.weight.data.clone()
#     model.conv1 = new_conv
#     del conv1
#     return model

def get_model(model_name, num_classes, pretrained='imagenet'):
    model_fn = pretrainedmodels.__dict__[model_name]
    model = model_fn(num_classes=1000, pretrained=pretrained)
    dim_feats = model.last_linear.in_features
    model.last_linear = nn.Sequential()
    conv1 = model.conv1
    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)
    new_conv.weight.data[:,0:3,:] = conv1.weight.data.clone()
    new_conv.weight.data[:,3:6,:] = conv1.weight.data.clone()
    model.conv1 = new_conv
    del conv1
    return model

def freeze_all(model):
    for param in model.parameters():
        param.requires_grad = False

def unfreeze_head(model):
    for param in model.last_linear.parameters():
        param.requires_grad = True

def get_layer(model, key):
    """Gets model layer using a key.

    The key could be hierarchical, like first.second.third where
    each dot separates hierarchy level.
    """
    parts = key.split('.')
    block = model
    for part in parts:
        block = getattr(block, part)
    return block

def unfreeze_layers(model, names):
    for name in names:
        layer = get_layer(model, name)
        print(f'Unfreezing layer {name}')
        for param in layer.parameters():
            param.requires_grad = True


data_dict = load_data()
trn_rec, tst_rec = data_dict['data']
num_classes = data_dict['num_classes']


cell_types = defaultdict(list)
for record in trn_rec:
    cell_types[record['cell_type']].append(record)

train, valid = [], []
for ct, records in cell_types.items():
    print(f'Splitting train/test for type: {ct}')
    labels = np.array([r['enc_sirna'] for r in records])
    ct_train, ct_valid = train_test_split(records, stratify=labels, test_size=0.2)
    train.extend(ct_train)
    valid.extend(ct_valid)
    print(f'... split counts: {len(ct_train)}/{len(ct_valid)} [total: {len(records)}]')

transforms = T.Compose(
    additional_targets={f'image{i}': 'image' for i in range(5)},
    transforms=[
        T.Resize(224, 224),
        T.VerticalFlip(p=0.25),
        T.HorizontalFlip(p=0.25),
        T.Normalize(mean=(0.5,), std=(0.5,))
    ]
)

batch_size = 650
trn_ds = Augmented(RxRxDataset(train, num_classes, onehot=True), tr=transforms)
val_ds = Augmented(RxRxDataset(valid, num_classes, onehot=True), tr=transforms)
loaders = dict(
    train=DataLoader(trn_ds, batch_size=batch_size, num_workers=12, shuffle=True),
    valid=DataLoader(val_ds, batch_size=batch_size, num_workers=12, shuffle=False)
)


class FocalLoss(nn.Module):
    def __init__(self, gamma=2, eps=1e-7):
        super().__init__()
        self.gamma = gamma
        self.eps = eps

    def forward(self, x, y):
        y_onehot = torch.eye(x.size(-1))[y.detach().clone()]
        logits = F.softmax(x.cpu(), dim=1).clamp(self.eps, 1 - self.eps)
        ce_loss = -1 * y_onehot * torch.log(logits)
        focal_loss = ce_loss * (1 - logits)**self.gamma
        return focal_loss.to(x.device).sum(dim=1).mean()


epochs = 50
lrs = 1e-5, 1e-4, 1e-3
model = get_model('resnet50', num_classes)
freeze_all(model)
unfreeze_layers(model, ['layer4', 'last_linear'])
conv_lr, layer_lr, head_lr = lrs
opt = torch.optim.AdamW(
    params=[
        # {'params': model.conv1.parameters(), 'lr': conv_lr},
        {'params': model.layer4.parameters(), 'lr': layer_lr},
        {'params': model.last_linear.parameters(), 'lr': head_lr}
    ],
    weight_decay=0.01
)
sched = CosineAnnealingWarmRestarts(opt, T_0=len(loaders['train']), T_mult=2, eta_min=1e-6)
loss_fn = nn.CrossEntropyLoss()
runner = SupervisedRunner()


runner.train(
    model=model,
    num_epochs=epochs,
    criterion=loss_fn,
    optimizer=opt,
    scheduler=sched,
    logdir='/tmp/cells_split/',
    loaders=loaders,
    callbacks=[
        AccuracyCallback(num_classes=num_classes),
        BatchMetricsPlotCallback(use_env_creds=True),
        EpochMetricsPlotCallback(use_env_creds=True)
    ],
    verbose=True
)
