{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: 04_dense_net.ipynb -> dense_net.py\r\n",
      "1 notebook(s) exported into folder: .\r\n"
     ]
    }
   ],
   "source": [
    "!python -m jupytools export -nb \"04_dense_net.ipynb\" -o ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import os\n",
    "from os.path import dirname, join\n",
    "from pdb import set_trace\n",
    "\n",
    "import jupytools\n",
    "import jupytools.syspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "jupytools.syspath.add(join(dirname(os.getcwd()), 'protein_project'))\n",
    "jupytools.syspath.add('rxrx1-utils')\n",
    "if jupytools.is_notebook():\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "else:\n",
    "    from tqdm import tqdm as tdqm\n",
    "    \n",
    "import contextlib, io\n",
    "with contextlib.redirect_stderr(io.StringIO()):\n",
    "    from augmentation import Augmented, multichannel_norm\n",
    "    from basedir import ROOT, NUM_CLASSES\n",
    "    from catalyst_visdom import BatchMetricsPlotCallback, EpochMetricsPlotCallback\n",
    "    from dataset import load_data, RxRxDataset\n",
    "    from model.utils import freeze_all, unfreeze_layers\n",
    "    from visual import rgb, six, show_1, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import albumentations as T\n",
    "\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "from catalyst.contrib.modules import GlobalConcatPool2d\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import AccuracyCallback, EarlyStoppingCallback\n",
    "from catalyst.dl.core import Callback\n",
    "from catalyst.utils import get_one_hot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "data_dict = load_data()\n",
    "trn_rec, tst_rec = data_dict['data']\n",
    "num_classes = data_dict['num_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experiments: ['HEPG2-01', 'HEPG2-02', 'HEPG2-03', 'HEPG2-04', 'HEPG2-05', 'HEPG2-07', 'HUVEC-01', 'HUVEC-02', 'HUVEC-03', 'HUVEC-04', 'HUVEC-05', 'HUVEC-06', 'HUVEC-07', 'HUVEC-08', 'HUVEC-09', 'HUVEC-10', 'HUVEC-11', 'HUVEC-13', 'HUVEC-14', 'HUVEC-15', 'HUVEC-16', 'RPE-01', 'RPE-02', 'RPE-03', 'RPE-04', 'RPE-06', 'RPE-07', 'U2OS-02', 'U2OS-03']\n",
      "Valid experiments: ['HEPG2-06', 'HUVEC-12', 'RPE-05', 'U2OS-01']\n",
      "Train size: 64166, valid size: 8864\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "with open('exp_channelwise_stats.json') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "experiments = np.unique([r['experiment'] for r in trn_rec])\n",
    "cell_types = np.unique([r['cell_type'] for r in trn_rec])\n",
    "holdouts = []\n",
    "for ct in cell_types:\n",
    "    holdout = np.random.choice(experiments[\n",
    "        [exp.startswith(ct) for exp in experiments]])\n",
    "    holdouts.append(holdout)\n",
    "    \n",
    "train_exp, valid_exp = [exp for exp in experiments if exp not in holdouts], holdouts\n",
    "print(f'Train experiments: {train_exp}')\n",
    "print(f'Valid experiments: {valid_exp}')\n",
    "train = [r for r in trn_rec if r['experiment'] in train_exp]\n",
    "valid = [r for r in trn_rec if r['experiment'] in valid_exp]\n",
    "print(f'Train size: {len(train)}, valid size: {len(valid)}')\n",
    "\n",
    "transforms = T.Compose(\n",
    "    additional_targets={f'image{i}': 'image' for i in range(5)},\n",
    "    transforms=[\n",
    "        T.Resize(224, 224), \n",
    "        T.VerticalFlip(p=0.25),\n",
    "        T.HorizontalFlip(p=0.25)\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trn_ds = Augmented(\n",
    "    RxRxDataset(train, NUM_CLASSES, onehot=True), \n",
    "    tr=transforms,\n",
    "    norm_fn=multichannel_norm,\n",
    "    norm_stats=stats\n",
    ")\n",
    "val_ds = Augmented(\n",
    "    RxRxDataset(valid, NUM_CLASSES, onehot=True), \n",
    "    tr=transforms,\n",
    "    norm_fn=multichannel_norm,\n",
    "    norm_stats=stats\n",
    ")\n",
    "loaders = OrderedDict([\n",
    "    ('train', DataLoader(trn_ds, batch_size=batch_size, num_workers=12, shuffle=True)),\n",
    "    ('valid', DataLoader(val_ds, batch_size=batch_size, num_workers=12, shuffle=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model_with_simple_custom_head(model_name, num_classes, pretrained='imagenet'):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "    conv0 = model.features.conv0\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    new_conv.weight.data[:, 0:3, :] = conv0.weight.data.clone()\n",
    "    new_conv.weight.data[:, 3:6, :] = conv0.weight.data.clone()\n",
    "    model.features.conv0 = new_conv\n",
    "    del conv0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing layer features.denseblock4.denselayer16\n",
      "Unfreezing layer last_linear\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "epochs = 1000\n",
    "model = get_model_with_simple_custom_head('densenet121', NUM_CLASSES)\n",
    "freeze_all(model)\n",
    "unfreeze_layers(model, ['features.denseblock4.denselayer16', 'last_linear'])\n",
    "opt = torch.optim.AdamW(\n",
    "    params=[\n",
    "        {'params': model.features.denseblock4.denselayer16.parameters(), 'lr': 1e-4},\n",
    "        {'params': model.last_linear.parameters(), 'lr': 1e-3}\n",
    "    ],\n",
    "    weight_decay=0.01\n",
    ")\n",
    "sched = CosineAnnealingWarmRestarts(opt, T_0=len(loaders['train']), T_mult=2, eta_min=1e-6)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "runner = SupervisedRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 01:11:15.121436 140092134479680 __init__.py:505] Setting up a new session...\n",
      "W0912 01:11:15.228921 140092134479680 __init__.py:505] Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early exiting                                                                                                                                                   \n",
      "0/1000 * Epoch (train):  14% 18/126 [00:39<02:20,  1.30s/it, _timers/_fps=2182.449, accuracy01=0.391, accuracy03=0.586, accuracy05=0.781, loss=7.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f692d746598>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ck/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ck/anaconda3/envs/fastai_10/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ck/anaconda3/envs/fastai_10/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ck/anaconda3/envs/fastai_10/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/ck/anaconda3/envs/fastai_10/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "runner.train(\n",
    "    model=model,\n",
    "    num_epochs=epochs,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=opt,\n",
    "    scheduler=sched,\n",
    "    logdir='/tmp/exp_split/',\n",
    "    loaders=loaders,\n",
    "    callbacks=[\n",
    "        AccuracyCallback(num_classes=NUM_CLASSES),\n",
    "        EarlyStoppingCallback(10, metric='accuracy01', minimize=False),\n",
    "        BatchMetricsPlotCallback(use_env_creds=True),\n",
    "        EpochMetricsPlotCallback(use_env_creds=True)\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data()\n",
    "_, test = data_dict['data']\n",
    "tst_ds = Augmented(\n",
    "    RxRxDataset(test, NUM_CLASSES, onehot=True), \n",
    "    tr=transforms,\n",
    "    norm_fn=multichannel_norm,\n",
    "    norm_stats=stats\n",
    ")\n",
    "tst_dl = DataLoader(tst_ds, batch_size=1024, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
