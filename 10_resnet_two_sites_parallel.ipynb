{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: 10_resnet_two_sites_parallel.ipynb -> resnet_two_sites_parallel.py\r\n",
      "1 notebook(s) exported into folder: .\r\n"
     ]
    }
   ],
   "source": [
    "!python -m jupytools export -nb \"10_resnet_two_sites_parallel.ipynb\" -o ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tanlikesmath/rcic-fastai-starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import os\n",
    "from os.path import dirname, join\n",
    "from functools import reduce\n",
    "from pdb import set_trace\n",
    "\n",
    "import cv2 as cv\n",
    "import jupytools\n",
    "import jupytools.syspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catalyst.utils import get_one_hot\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from visdom import Visdom\n",
    "\n",
    "jupytools.syspath.add(join(dirname(os.getcwd()), 'protein_project'))\n",
    "jupytools.syspath.add('rxrx1-utils')\n",
    "if jupytools.is_notebook():\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "else:\n",
    "    from tqdm import tqdm as tdqm\n",
    "    \n",
    "import contextlib, io\n",
    "with contextlib.redirect_stderr(io.StringIO()):\n",
    "    from basedir import ROOT, NUM_CLASSES\n",
    "    from catalyst_visdom import BatchMetricsPlotCallback, EpochMetricsPlotCallback\n",
    "    from dataset import load_data, build_stats_index, RxRxDataset\n",
    "    from model.utils import freeze_all, unfreeze_layers\n",
    "    from visual import rgb, six, show_1, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from augmentation import JoinChannels, SwapChannels, Resize, ToFloat, Rescale\n",
    "from augmentation import VerticalFlip, HorizontalFlip, PixelStatsNorm, composer\n",
    "from augmentation import AugmentedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RxRxImages(Dataset):\n",
    "    def __init__(self, meta_df, img_dir, site=1, channels=(1, 2, 3, 4, 5, 6), \n",
    "                 open_image=PIL.Image.open, n_classes=NUM_CLASSES, train=True):\n",
    "        \n",
    "        self.records = meta_df.to_records(index=False)\n",
    "        self.img_dir = img_dir\n",
    "        self.site = site\n",
    "        self.channels = channels\n",
    "        self.n = len(self.records)\n",
    "        self.open_image = open_image\n",
    "        self.n_classes = n_classes\n",
    "        self.train = train\n",
    "        \n",
    "    def _get_image_path(self, index, channel):\n",
    "        r = self.records[index]\n",
    "        exp, plate, well = r.experiment, r.plate, r.well\n",
    "        subdir = 'train' if self.train else 'test'\n",
    "        path = f'{self.img_dir}/{subdir}/{exp}/Plate{plate}/{well}_s{self.site}_w{channel}.png'\n",
    "        return path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        paths = [self._get_image_path(index, ch) for ch in self.channels]\n",
    "        img = np.stack([self.open_image(p) for p in paths])\n",
    "        img = img.astype(np.float32)\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        r = self.records[index]\n",
    "        if self.train:\n",
    "            sirna = r.sirna\n",
    "            target = int(sirna)\n",
    "            onehot = get_one_hot(target, num_classes=self.n_classes)\n",
    "            return {'features': img, 'targets': target, 'targets_one_hot': onehot}\n",
    "        else:\n",
    "            id_code = r.id_code\n",
    "            return {'features': img, 'id_code': id_code}\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TwoSiteImages(Dataset):\n",
    "    def __init__(self, ds1, ds2):\n",
    "        assert len(ds1) == len(ds2)\n",
    "        self.ds1, self.ds2 = ds1, ds2\n",
    "        self.size = len(ds1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return {'site1': self.ds1[index], 'site2': self.ds2[index]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from split import StratifiedSplit\n",
    "splitter = StratifiedSplit()\n",
    "trn_df, val_df = splitter(pd.read_csv(ROOT/'train.csv')) \n",
    "tst_df = pd.read_csv(ROOT/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "sz = 512\n",
    "trn_ds = TwoSiteImages(\n",
    "    ds1=AugmentedImages(ds=RxRxImages(trn_df, ROOT, site=1), tr=composer(resize=sz)),\n",
    "    ds2=AugmentedImages(ds=RxRxImages(trn_df, ROOT, site=2), tr=composer(resize=sz))\n",
    ")\n",
    "val_ds = TwoSiteImages(\n",
    "    ds1=AugmentedImages(ds=RxRxImages(val_df, ROOT, site=1), tr=composer(resize=sz)),\n",
    "    ds2=AugmentedImages(ds=RxRxImages(val_df, ROOT, site=2), tr=composer(resize=sz))\n",
    ")\n",
    "tst_ds = TwoSiteImages(\n",
    "    ds1=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=1, train=False), tr=composer(resize=sz)),\n",
    "    ds2=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=2, train=False), tr=composer(resize=sz))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def new_loader(ds, bs, shuffle=True, num_workers=12):\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet18(head_fn=None, n_classes=NUM_CLASSES):\n",
    "    model_fn = pretrainedmodels.__dict__['resnet18']\n",
    "    model = model_fn(num_classes=1000, pretrained='imagenet')\n",
    "    feat_dim = model.last_linear.in_features\n",
    "    if head_fn is None:\n",
    "        model.last_linear = nn.Linear(feat_dim, n_classes)\n",
    "    else:\n",
    "        model.last_linear = head_fn(feat_dim)\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    conv1 = model.conv1.weight\n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:, :] = torch.stack([torch.mean(conv1, 1)]*6, dim=1)\n",
    "    model.conv1 = new_conv\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet18_TwoSites(nn.Module):\n",
    "    def __init__(self, n_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        \n",
    "        def head(in_features): \n",
    "            return nn.Linear(in_features, in_features)\n",
    "        \n",
    "        self.m1 = resnet18(head_fn=head)\n",
    "        self.m2 = resnet18(head_fn=head)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.top = nn.Linear(self.m1.last_linear.out_features * 2, n_classes)\n",
    "    \n",
    "    def forward(self, s1, s2):\n",
    "        out1 = self.m1(s1)\n",
    "        out2 = self.m2(s2)\n",
    "        concat = torch.cat([out1, out2], dim=1)\n",
    "        out = self.top(self.relu(self.drop(concat)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def freeze_all(model):\n",
    "    for name, child in model.named_children():\n",
    "        print('Freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze_all(model):\n",
    "    for name, child in model.named_children():\n",
    "        print('Un-freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze(model, names):\n",
    "    for name, child in model.named_children():\n",
    "        if name not in names:\n",
    "            continue\n",
    "        print('Un-freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model = ResNet18_TwoSites()\n",
    "freeze_all(model.m1)\n",
    "freeze_all(model.m2)\n",
    "freeze_all(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RollingLoss:\n",
    "    def __init__(self, smooth=0.98):\n",
    "        self.smooth = smooth\n",
    "        self.prev = 0\n",
    "    def __call__(self, curr, batch_no):\n",
    "        a = self.smooth\n",
    "        avg_loss = a*self.prev + (1 - a)*curr\n",
    "        debias_loss = avg_loss/(1 - a**batch_no)\n",
    "        self.prev = avg_loss\n",
    "        return debias_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_loaders(batch_size):\n",
    "    trn_dl = new_loader(trn_ds, bs=batch_size, shuffle=True)\n",
    "    val_dl = new_loader(val_ds, bs=batch_size, shuffle=False)\n",
    "    return OrderedDict([('train', trn_dl), ('valid', val_dl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "epochs = 1000\n",
    "patience = 500\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "sched = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.95)\n",
    "model = model.to(device)\n",
    "rolling_loss = dict(train=RollingLoss(), valid=RollingLoss())\n",
    "steps = dict(train=0, valid=0)\n",
    "\n",
    "trials = 0\n",
    "best_metric = -np.inf\n",
    "history = []\n",
    "stop = False\n",
    "\n",
    "vis = Visdom(server='0.0.0.0', port=9091,\n",
    "             username=os.environ['VISDOM_USERNAME'],\n",
    "             password=os.environ['VISDOM_PASSWORD'])\n",
    "\n",
    "loaders = create_loaders(batch_size=32)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f'Epoch [{epoch}/{epochs}]')\n",
    "    \n",
    "    if epoch == 1:\n",
    "        unfreeze_layers(model, ['m1.last_linear', 'm2.last_linear', 'top'])\n",
    "    elif epoch == 5:\n",
    "        unfreeze_all(model.m1)\n",
    "        unfreeze_all(model.m2)\n",
    "        unfreeze_all(model)\n",
    "    \n",
    "    curr_lr = opt.param_groups[0]['lr']\n",
    "    vis.line(X=[epoch], Y=[curr_lr], win='lr', name='lr', update='append')    \n",
    "    iteration = dict(epoch=epoch, train_loss=list(), valid_loss=list())\n",
    "    print(f\"Current learning rate: {opt.param_groups[0]['lr']:.2E}\")\n",
    "    \n",
    "    for name, loader in loaders.items():\n",
    "        is_training = name == 'train'\n",
    "        count = 0\n",
    "        metric = 0.0\n",
    "        \n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            for batch in loader:\n",
    "                steps[name] += 1\n",
    "                opt.zero_grad()\n",
    "                #x = batch['features'].to(device)\n",
    "                #y = batch['targets'].to(device)\n",
    "                #out = model(x)\n",
    "                y = batch['site1']['targets'].to(device)\n",
    "          \n",
    "                out = model(\n",
    "                    batch['site1']['features'].to(device),\n",
    "                    batch['site2']['features'].to(device)\n",
    "                )\n",
    "                \n",
    "                if is_training:\n",
    "                    loss = loss_fn(out, y)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                \n",
    "                avg_loss = rolling_loss[name](loss.item(), steps[name])\n",
    "                iteration[f'{name}_loss'].append(avg_loss)\n",
    "                y_pred = out.softmax(dim=1).argmax(dim=1)\n",
    "                acc = (y_pred == y).float().mean().item()\n",
    "                metric += acc\n",
    "                count += len(batch)\n",
    "                vis.line(X=[steps[name]], Y=[avg_loss], name=f'{name}_loss', \n",
    "                         win=f'{name}_loss', update='append', \n",
    "                         opts=dict(title=f'Running Loss [{name}]'))\n",
    "        \n",
    "        metric /= count\n",
    "        iteration[f'{name}_acc'] = metric\n",
    "        vis.line(X=[epoch], Y=[avg_loss], name=f'{name}', win='avg_loss',\n",
    "                 update='append', opts=dict(title='Average Epoch Loss'))\n",
    "        vis.line(X=[epoch], Y=[metric], name=f'{name}', win='accuracy', \n",
    "                 update='append', opts=dict(title=f'Accuracy'))\n",
    "        \n",
    "        last_loss = iteration[f'{name}_loss'][-1]\n",
    "        \n",
    "        print(f'{name} metrics: accuracy={metric:2.3%}, loss={last_loss:.4f}')\n",
    "          \n",
    "        if is_training:\n",
    "            sched.step()\n",
    "          \n",
    "        else:\n",
    "            # sched.step(metric)\n",
    "            if metric > best_metric:\n",
    "                trials = 0\n",
    "                best_metric = metric\n",
    "                print('Score improved!')\n",
    "                torch.save(model.state_dict(), f'two_sites/train.{epoch}.pth')\n",
    "            else:\n",
    "                trials += 1\n",
    "                if trials >= patience:\n",
    "                    stop = True\n",
    "                    break\n",
    "    \n",
    "    history.append(iteration)\n",
    "    \n",
    "    print('-' * 80)\n",
    "    \n",
    "    if stop:\n",
    "        print(f'Early stopping on epoch: {epoch}')\n",
    "        break\n",
    "\n",
    "torch.save(history, 'history.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = resnet18()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('train.9.pth'))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_dl = new_loader(tst_ds, bs=64)\n",
    "    preds = {}\n",
    "    for batch in tqdm(test_dl):\n",
    "        out = model(batch['features'].to(device))\n",
    "        y_hat = out.argmax(dim=-1).cpu().numpy()\n",
    "        preds.update(dict(zip(batch['id_code'], y_hat.astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame([\n",
    "    {'id_code': id_code, 'sirna': sirna} \n",
    "    for id_code, sirna in preds.items()])\n",
    "preds_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds_df.to_csv('submit.csv', index=False, columns=['id_code', 'sirna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(ROOT/'test.csv')\n",
    "submit['sirna'] = preds.astype(int)\n",
    "submit.to_csv('submit.csv', index=False, columns=['id_code','sirna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
