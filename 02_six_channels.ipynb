{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0831 20:10:45.944396 140527749310272 compression.py:14] lz4 not available, disabling compression. To install lz4, run `pip install lz4`.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import json\n",
    "from multiprocessing import cpu_count\n",
    "import re\n",
    "import sys\n",
    "from pdb import set_trace\n",
    "from pprint import pprint as pp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ancli\n",
    "from imageio import imread\n",
    "from jupytools import auto_set_trace, is_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from tqdm import tqdm\n",
    "import pretrainedmodels\n",
    "from visdom import Visdom\n",
    "\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "from catalyst.data.dataset import ListDataset\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.utils import get_one_hot\n",
    "\n",
    "try:\n",
    "    extended\n",
    "except NameError:\n",
    "    sys.path.insert(0, 'rxrx1-utils')\n",
    "    import rxrx.io as rio\n",
    "    \n",
    "from basedir import ROOT, TRAIN, TEST, SAMPLE, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of set_trace(): ipdb\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "seed = 1\n",
    "dev_id = 0\n",
    "device = torch.device(dev_id)\n",
    "set_trace = auto_set_trace()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = f'{dev_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load meta-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def list_files(folder):\n",
    "    dirname = os.path.expanduser(folder)\n",
    "    return [os.path.join(dirname, x) for x in os.listdir(dirname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data():\n",
    "    content = []\n",
    "    for filename in ('train', 'test'):\n",
    "        with open(f'{filename}.json') as f:\n",
    "            content.append(json.load(f))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RxRxDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, items, onehot=True,\n",
    "                 label_smoothing=None,\n",
    "                 open_fn=PIL.Image.open, tr=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.onehot = onehot\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.open_fn = open_fn\n",
    "        self.tr = tr\n",
    "        self.targets = [item['sirna'] for item in items]\n",
    "        self.images = [item['images'] for item in items]\n",
    "        self.num_classes = len(np.unique(self.targets))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        bunch = self.images[index]\n",
    "        channels = []\n",
    "        for i, filename in sorted(bunch, key=itemgetter(0)):\n",
    "            img = self.open_fn(filename)\n",
    "            img = img if self.tr is None else self.tr(img)\n",
    "            channels.append(img)\n",
    "        sample = torch.cat(channels, dim=0)\n",
    "        y = self.targets[index]\n",
    "        sample = dict(features=sample, targets=y)\n",
    "        if self.onehot:\n",
    "            y_enc = get_one_hot(\n",
    "                y, smoothing=self.label_smoothing, \n",
    "                num_classes=self.num_classes)\n",
    "            sample['targets_one_hot'] = y_enc\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_data_loaders(train_records, test_records, batch_size=4):\n",
    "    ys = [r['sirna'] for r in train_records]\n",
    "    train, valid = train_test_split(train_records, stratify=ys, test_size=0.1)\n",
    "    trn_ds = RxRxDataset(train, tr=T.Compose([\n",
    "        T.Resize(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5,), (0.5,))\n",
    "    ]))\n",
    "    val_ds = RxRxDataset(valid, tr=T.Compose([\n",
    "        T.Resize(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5,), (0.5,))\n",
    "    ]))\n",
    "    tst_ds = RxRxDataset(test_records, onehot=False, tr=T.Compose([\n",
    "        T.Resize(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5,), (0.5,))\n",
    "    ]))\n",
    "    trn_dl = DataLoader(\n",
    "        trn_ds, shuffle=True, \n",
    "        batch_size=batch_size, num_workers=cpu_count())\n",
    "    val_dl = DataLoader(\n",
    "        val_ds, shuffle=False,\n",
    "        batch_size=batch_size, num_workers=cpu_count())\n",
    "    tst_dl = DataLoader(\n",
    "        tst_ds, shuffle=False,\n",
    "        batch_size=batch_size, num_workers=cpu_count())\n",
    "    loaders = OrderedDict()\n",
    "    loaders['train'] = trn_dl\n",
    "    loaders['valid'] = val_dl\n",
    "    loaders['test'] = tst_dl\n",
    "    return {'loaders': loaders, 'num_classes': NUM_CLASSES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model_name = 'resnet34'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plus_noise(t, std=0.001):\n",
    "    return t + torch.randn(t.shape)*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(model_name, num_classes, pretrained='imagenet'):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    new_conv.weight.data[:,0:3,:] = plus_noise(model.conv1.weight.data.clone())\n",
    "    new_conv.weight.data[:,3:6,:] = plus_noise(model.conv1.weight.data.clone())\n",
    "    model.conv1 = new_conv\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RollingLoss:\n",
    "    def __init__(self, smooth=0.98):\n",
    "        self.smooth = smooth\n",
    "        self.prev = 0\n",
    "    def __call__(self, curr, batch_no):\n",
    "        a = self.smooth\n",
    "        avg_loss = a*self.prev + (1 - a)*curr\n",
    "        debias_loss = avg_loss/(1 - a**batch_no)\n",
    "        self.prev = avg_loss\n",
    "        return debias_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_layer(model, key):\n",
    "    \"\"\"Gets model layer using a key.\n",
    "    \n",
    "    The key could be hierarchical, like first.second.third where\n",
    "    each dot separates hierarchy level.\n",
    "    \"\"\"\n",
    "    parts = key.split('.')\n",
    "    block = model\n",
    "    for part in parts:\n",
    "        block = getattr(block, part)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze_layers(model, names):\n",
    "    for name in names:\n",
    "        layer = get_layer(model, name)\n",
    "        print(f'Unfreezing layer {name}')\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(epochs: int=1,\n",
    "          batch_size: int=800, \n",
    "          model_name: str='resnet34', \n",
    "          logdir: str='/tmp/loops/',\n",
    "          lrs: tuple=(1e-5, 1e-3, 5e-3),\n",
    "          eta_min: float=1e-6,\n",
    "          dev_id: int=1,\n",
    "          visdom_host: str='0.0.0.0',\n",
    "          visdom_port: int=9001):\n",
    "    \n",
    "    vis = Visdom(server=visdom_host, port=visdom_port,\n",
    "                 username=os.environ['VISDOM_USERNAME'],\n",
    "                 password=os.environ['VISDOM_PASSWORD'])\n",
    "    \n",
    "    experiment_id = f'{model_name}_e{epochs}_b{batch_size}'\n",
    "    device = torch.device(f'cuda:{dev_id}')\n",
    "    dataset = create_data_loaders(*load_data(), batch_size=batch_size)\n",
    "    model = get_model(model_name, dataset['num_classes']).to(device)\n",
    "    freeze_model(model)\n",
    "    unfreeze_layers(model, ['conv1', 'bn1', 'layer4', 'last_linear'])\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    conv, layer, head = lrs\n",
    "    opt = torch.optim.SGD([\n",
    "        {'params': model.conv1.parameters(), 'lr': conv},\n",
    "        {'params': model.layer4.parameters(), 'lr': layer},\n",
    "        {'params': model.last_linear.parameters(), 'lr': head}\n",
    "    ])\n",
    "    logdir = os.path.join(logdir, experiment_id)\n",
    "    sched = CosineAnnealingWarmRestarts(\n",
    "        opt, T_0=len(dataset['loaders']['train']), T_mult=2, eta_min=eta_min)\n",
    "    rolling_loss = RollingLoss()\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        trn_dl = dataset['loaders']['train']\n",
    "        n = len(trn_dl)\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(total=n) as bar:\n",
    "            for i, batch in enumerate(trn_dl, 1):\n",
    "                iteration += 1\n",
    "                if i % 25 == 0:\n",
    "                    for j, g in enumerate(opt.param_groups):\n",
    "                        vis.line(X=[iteration], Y=[g['lr']], \n",
    "                                 win=f'metrics{j}', name=f'lr{j}', update='append')\n",
    "                bar.set_description(f'[epoch:{epoch}/{epochs}][{i}/{n}]')\n",
    "                opt.zero_grad()\n",
    "                x = batch['features'].to(device)\n",
    "                y = batch['targets'].to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, y)\n",
    "                loss.backward()\n",
    "                avg_loss = rolling_loss(loss.item(), i+1)\n",
    "                opt.step()\n",
    "                sched.step()\n",
    "                bar.set_postfix(avg_loss=f'{avg_loss:.3f}')\n",
    "                bar.update(1)\n",
    "                vis.line(X=[iteration], Y=[avg_loss],\n",
    "                         win='loss', name='avg_loss', update='append')\n",
    "\n",
    "        val_dl = dataset['loaders']['valid']\n",
    "        n = len(val_dl)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            matches = []\n",
    "            with tqdm(total=n) as bar:\n",
    "                for batch in val_dl:\n",
    "                    x = batch['features'].to(device)\n",
    "                    y = batch['targets'].to(device)\n",
    "                    out = model(x)\n",
    "                    y_pred = out.softmax(dim=1).argmax(dim=1)\n",
    "                    matched = (y == y_pred).detach().cpu().numpy().tolist()\n",
    "                    matches.extend(matched)\n",
    "                    bar.update(1)\n",
    "            acc = np.mean(matches)\n",
    "            vis.line(X=[epoch], Y=[acc], win='acc', name='val_acc', update='append')\n",
    "            print(f'validation accuracy: {acc:2.2%}')\n",
    "            acc_str = str(int(round(acc * 10_000, 0)))\n",
    "            path = os.path.join(logdir, f'train.{epoch}.{acc_str}.pth')\n",
    "            torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    if not is_notebook():\n",
    "        ancli.make_cli(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 20:10:46.773514 140527749310272 __init__.py:505] Setting up a new session...\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing layer conv1\n",
      "Unfreezing layer bn1\n",
      "Unfreezing layer layer4\n",
      "Unfreezing layer last_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch:1/1][286/286]: 100%|██████████| 286/286 [03:48<00:00,  1.87it/s, avg_loss=7.153]\n",
      "100%|██████████| 32/32 [00:27<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.14%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f823c19c6096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet34'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-f31212378b88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, model_name, logdir, lrs, eta_min, dev_id, visdom_host, visdom_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0macc_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'train.{epoch}.{acc_str}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet' is not defined"
     ]
    }
   ],
   "source": [
    "train(model_name='resnet34', batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "epochs = 30\n",
    "batch_size = 800\n",
    "dataset = create_data_loaders(*load_data(), batch_size=batch_size)\n",
    "model = get_model(model_name, dataset['num_classes']).to(device)\n",
    "freeze_model(resnet)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet.conv1.requires_grad = False\n",
    "resnet.last_linear.weight.requires_grad = True\n",
    "for param in resnet.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD([\n",
    "    {'params': resnet.conv1.parameters(), 'lr': 1e-6},\n",
    "    {'params': resnet.layer4.parameters(), 'lr': 1e-3},\n",
    "    {'params': resnet.last_linear.parameters(), 'lr': 5e-3}\n",
    "])\n",
    "\n",
    "# logdir = '/tmp/protein/logs/'\n",
    "logdir = '/tmp/loops/protein/'\n",
    "runner = SupervisedRunner()\n",
    "sched = CosineAnnealingWarmRestarts(opt, len(dataset['loaders']['train']), eta_min=1e-7)\n",
    "rolling_loss = RollingLoss()\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    trn_dl = dataset['loaders']['train']\n",
    "    n = len(trn_dl)\n",
    "    \n",
    "    resnet.train()\n",
    "    with tqdm(total=n) as bar:\n",
    "        for i, batch in enumerate(trn_dl, 1):\n",
    "            bar.set_description(f'[epoch:{epoch}][{i}/{n}]')\n",
    "            opt.zero_grad()\n",
    "            x = batch['features'].to(device)\n",
    "            y = batch['targets'].to(device)\n",
    "            out = resnet(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            avg_loss = rolling_loss(loss.item(), i+1)\n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            bar.set_postfix(avg_loss=f'{avg_loss:.3f}')\n",
    "            bar.update(1)\n",
    "            \n",
    "    val_dl = dataset['loaders']['valid']\n",
    "    n = len(val_dl)\n",
    "    \n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        matches = []\n",
    "        with tqdm(total=n) as bar:\n",
    "            for batch in val_dl:\n",
    "                x = batch['features'].to(device)\n",
    "                y = batch['targets'].to(device)\n",
    "                out = resnet(x)\n",
    "                y_pred = out.softmax(dim=1).argmax(dim=1)\n",
    "                set_trace()\n",
    "                matched = (y == y_pred).detach().cpu().numpy().tolist()\n",
    "                matches.extend(matched)\n",
    "                bar.update(1)\n",
    "        acc = np.mean(matches)\n",
    "        print(f'validation accuracy: {acc:2.2%}')\n",
    "        acc_str = str(int(round(acc * 10_000, 0)))\n",
    "        torch.save(resnet.state_dict(), os.path.join(logdir, f'train.{epoch}.{acc_str}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: report issue with one-hot smoothing AUC and accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_name, NUM_CLASSES)\n",
    "checkpoints = []\n",
    "checkpoints_path = '/tmp/loops/protein/'\n",
    "for filename in os.listdir(checkpoints_path):\n",
    "    _, acc, _, _ = filename.split('.')\n",
    "    checkpoints.append((os.path.join(checkpoints_path, filename), int(acc)))\n",
    "checkpoints.sort(key=itemgetter(1))\n",
    "best, _ = checkpoints[-1]\n",
    "model.load_state_dict(torch.load(best))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_data_loaders(*load_data(), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "preds = []\n",
    "for batch in tqdm(dataset['loaders']['test']):\n",
    "    out = model(batch['features'].to(device))\n",
    "    y = out.softmax(dim=1)\n",
    "    preds.extend(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(list_files('~/data/protein/tmp/test'))\n",
    "\n",
    "# odd\n",
    "site1 = []\n",
    "for filename, pred in list(zip(filenames, preds))[::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site1.append(pred)\n",
    "    \n",
    "# even\n",
    "site2 = []\n",
    "for filename, pred in list(zip(filenames, preds))[1::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(site1)\n",
    "t2 = torch.tensor(site2)\n",
    "avg_pred = ((t1 + t2)/2).argmax(dim=1)\n",
    "print(avg_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/home/ck/data/protein/sample_submission.csv')\n",
    "sample['sirna'] = avg_pred.tolist()\n",
    "sample.to_csv('submit.csv', index=False)\n",
    "from IPython.display import FileLink\n",
    "FileLink('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# print('Saving the trained model')\n",
    "# basedir = os.path.expanduser('~/data/protein/tmp/models')\n",
    "# os.makedirs(basedir)\n",
    "# torch.save(resnet, os.path.join(basedir, 'resnet50_simple.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
