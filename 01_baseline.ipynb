{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 23:01:10.188656 140535679878976 compression.py:14] lz4 not available, disabling compression. To install lz4, run `pip install lz4`.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import re\n",
    "from pdb import set_trace\n",
    "from multiprocessing import cpu_count\n",
    "from pprint import pprint as pp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "from catalyst.data.dataset import ListDataset\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "import pretrainedmodels\n",
    "from jupytools import auto_set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of set_trace(): ipdb\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "seed = 1\n",
    "set_trace = auto_set_trace()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def list_files(folder):\n",
    "    dirname = os.path.expanduser(folder)\n",
    "    return [os.path.join(dirname, x) for x in os.listdir(dirname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_labels(files):\n",
    "    regex = re.compile('.*_(\\d+)\\\\.png$')\n",
    "    return [int(regex.match(os.path.basename(fn)).group(1)) for fn in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "uniq_labels = np.unique(extract_labels(list_files('~/data/protein/tmp/train')))\n",
    "num_classes = len(uniq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_range': [0, 1],\n",
      " 'input_size': [3, 224, 224],\n",
      " 'input_space': 'RGB',\n",
      " 'mean': [0.485, 0.456, 0.406],\n",
      " 'num_classes': 1000,\n",
      " 'std': [0.229, 0.224, 0.225],\n",
      " 'url': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'}\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from typing import List, Dict, Callable, Any\n",
    "\n",
    "class PathsDataset(ListDataset):\n",
    "    \"\"\"\n",
    "    Dataset that derives features and targets from samples filesystem paths.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames: List[Dict],\n",
    "        open_fn: Callable,\n",
    "        get_label_fn: Callable,\n",
    "        **list_dataset_params\n",
    "    ):\n",
    "        list_data = [\n",
    "            {'features': filename, \n",
    "             'targets': get_label_fn(filename)}\n",
    "            for filename in filenames]\n",
    "        \n",
    "        super().__init__(\n",
    "            list_data=list_data,\n",
    "            open_fn=open_fn,\n",
    "            **list_dataset_params\n",
    "        )\n",
    "        \n",
    "class RegexLabelExtractor:\n",
    "    def __init__(self, regex):\n",
    "        self.regex = re.compile(regex)\n",
    "\n",
    "    def __call__(self, filename):\n",
    "        return int(self.regex.match(os.path.basename(filename)).group(1))\n",
    "    \n",
    "class ImageTransformer:\n",
    "    def __init__(self, image_tr: Callable):\n",
    "        self.image_tr = image_tr\n",
    "    \n",
    "    def __call__(self, dict_):\n",
    "        dict_ = dict_.copy()\n",
    "        dict_['features'] = self.image_tr(dict_['features'])\n",
    "        return dict_\n",
    "    \n",
    "class OneHotTransformer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def __call__(self, dict_):\n",
    "        y = dict_['targets']\n",
    "        onehot = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        onehot[y] = 1\n",
    "        dict_['targets_one_hot'] = onehot\n",
    "        return dict_\n",
    "    \n",
    "class TransformerList:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, dict_):\n",
    "        from functools import reduce\n",
    "        return reduce(lambda x, f: f(x), self.transforms, dict_)\n",
    "        \n",
    "def open_image(dict_):\n",
    "    dict_ = dict_.copy()\n",
    "    dict_['features'] = PIL.Image.open(dict_['features'])\n",
    "    return dict_\n",
    "\n",
    "model_name = 'resnet50'\n",
    "params = pretrainedmodels.pretrained_settings[model_name]['imagenet']\n",
    "pp(params)\n",
    "\n",
    "transformers = TransformerList([\n",
    "    ImageTransformer(T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(params['mean'], params['std'])\n",
    "    ])),\n",
    "    OneHotTransformer(num_classes)\n",
    "])\n",
    "\n",
    "labelled_files = list_files('~/data/protein/tmp/train')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trn_files, tst_files = train_test_split(labelled_files, test_size=0.1, random_state=seed)\n",
    "regex_label = RegexLabelExtractor('.*_(\\d+)\\\\.png$')\n",
    "\n",
    "trn_ds = PathsDataset(\n",
    "    filenames=trn_files,\n",
    "    open_fn=open_image,\n",
    "    get_label_fn=regex_label,\n",
    "    dict_transform=transformers\n",
    ")\n",
    "\n",
    "val_ds = PathsDataset(\n",
    "    filenames=tst_files,\n",
    "    open_fn=open_image,\n",
    "    get_label_fn=regex_label,\n",
    "    dict_transform=transformers\n",
    ")\n",
    "\n",
    "batch_size = 800\n",
    "loaders = OrderedDict()\n",
    "loaders['train'] = DataLoader(trn_ds, shuffle=True, batch_size=batch_size)\n",
    "loaders['valid'] = DataLoader(val_ds, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(model_name, num_classes, pretrained='imagenet'):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "epochs = 20\n",
    "\n",
    "resnet = get_model(model_name, num_classes)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet.last_linear.weight.requires_grad = True\n",
    "for param in resnet.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(resnet.parameters(), lr=0.01, weight_decay=0.01)\n",
    "logdir = '/tmp/protein/logs/'\n",
    "runner = SupervisedRunner()\n",
    "sched = OneCycleLR(opt, \n",
    "                   num_steps=epochs * len(loaders['train']),\n",
    "                   warmup_fraction=0.2,\n",
    "                   lr_range=(0.1, 0.01, 0.001))\n",
    "\n",
    "runner.train(\n",
    "    model=resnet,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=opt,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=epochs,\n",
    "    scheduler=sched,\n",
    "    callbacks=[\n",
    "        AccuracyCallback(num_classes=num_classes),\n",
    "        AUCCallback(\n",
    "            num_classes=num_classes,\n",
    "            input_key=\"targets_one_hot\"\n",
    "        ),\n",
    "        F1ScoreCallback(\n",
    "            input_key=\"targets_one_hot\",\n",
    "            activation=\"Softmax\"\n",
    "        )\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "print('Saving the trained model')\n",
    "basedir = os.path.expanduser('~/data/protein/tmp/models')\n",
    "os.makedirs(basedir)\n",
    "torch.save(resnet, os.path.join(basedir, 'resnet50_simple.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = get_model(model_name, num_classes).cuda(0)\n",
    "restored = torch.load('/tmp/protein/logs/checkpoints/best.pth')\n",
    "resnet.load_state_dict(restored['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7592e401ac44e339af45a93b27a36b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "resnet.eval()\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "filenames = sorted(list_files('~/data/protein/tmp/test'))\n",
    "    \n",
    "tst_ds = PathsDataset(\n",
    "    filenames=filenames,\n",
    "    open_fn=open_image,\n",
    "    get_label_fn=regex_label,\n",
    "    dict_transform=transformers\n",
    ")\n",
    "\n",
    "tst_dl = DataLoader(tst_ds, batch_size=512, num_workers=cpu_count())\n",
    "preds = []\n",
    "for batch in tqdm(tst_dl):\n",
    "    out = resnet(batch['features'].cuda(0))\n",
    "    y = out.softmax(dim=1)\n",
    "    preds.extend(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site1 = torch.tensor(preds[::2])\n",
    "# site2 = torch.tensor(preds[1::2])\n",
    "# avg_pred = ((site1 + site2)/2).argmax(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = []\n",
    "# for filename, pred in list(zip(filenames, avg_pred)):\n",
    "#     basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "#     sirna = int(basename.split('_')[-1])\n",
    "#     if sirna != 0: continue\n",
    "#     submission.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odd\n",
    "site1 = []\n",
    "for filename, pred in list(zip(filenames, preds))[::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site1.append(pred)\n",
    "    \n",
    "# even\n",
    "site2 = []\n",
    "for filename, pred in list(zip(filenames, preds))[1::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19897])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor(site1)\n",
    "t2 = torch.tensor(site2)\n",
    "avg_pred = ((t1 + t2)/2).argmax(dim=1)\n",
    "print(avg_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submit.csv' target='_blank'>submit.csv</a><br>"
      ],
      "text/plain": [
       "/home/ck/code/tasks/protein/submit.csv"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('/home/ck/data/protein/sample_submission.csv')\n",
    "sample['sirna'] = avg_pred.tolist()\n",
    "sample.to_csv('submit.csv', index=False)\n",
    "from IPython.display import FileLink\n",
    "FileLink('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # odd\n",
    "# site1 = []\n",
    "# for filename, pred in list(zip(filenames, preds))[::2]:\n",
    "#     basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "#     sirna = int(basename.split('_')[-1])\n",
    "#     if sirna != 0: \n",
    "#         continue\n",
    "#     site1.append(pred)\n",
    "    \n",
    "# # even\n",
    "# site2 = []\n",
    "# for filename, pred in list(zip(filenames, preds))[1::2]:\n",
    "#     basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "#     sirna = int(basename.split('_')[-1])\n",
    "#     if sirna != 0: \n",
    "#         continue\n",
    "#     site2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = pd.read_csv('/home/ck/data/protein/sample_submission.csv')\n",
    "# sample['sirna'] = site1\n",
    "# sample.to_csv('submit1.csv', index=False)\n",
    "# sample['sirna'] = site2\n",
    "# sample.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submit1.csv' target='_blank'>submit1.csv</a><br>"
      ],
      "text/plain": [
       "/home/ck/code/tasks/protein/submit1.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='submit2.csv' target='_blank'>submit2.csv</a><br>"
      ],
      "text/plain": [
       "/home/ck/code/tasks/protein/submit2.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(FileLink('submit1.csv'))\n",
    "# display(FileLink('submit2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/catalyst-team/catalyst/blob/master/examples/notebooks/notebook-example.ipynb\n",
    "# https://github.com/catalyst-team/catalyst/blob/master/examples/notebooks/classification-tutorial.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
