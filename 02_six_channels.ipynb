{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import json\n",
    "from multiprocessing import cpu_count\n",
    "import re\n",
    "import sys\n",
    "from pdb import set_trace\n",
    "from pprint import pprint as pp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ancli\n",
    "from imageio import imread\n",
    "from jupytools import auto_set_trace, is_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from tqdm import tqdm\n",
    "import pretrainedmodels\n",
    "from visdom import Visdom\n",
    "\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "from catalyst.data.dataset import ListDataset\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.utils import get_one_hot\n",
    "\n",
    "try:\n",
    "    extended\n",
    "except NameError:\n",
    "    sys.path.insert(0, 'rxrx1-utils')\n",
    "    import rxrx.io as rio\n",
    "    \n",
    "from basedir import ROOT, TRAIN, TEST, SAMPLE, NUM_CLASSES\n",
    "from data_bunch import DataBunch, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of set_trace(): ipdb\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "seed = 1\n",
    "dev_id = 0\n",
    "device = torch.device(dev_id)\n",
    "set_trace = auto_set_trace()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = f'{dev_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model_name = 'resnet50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(model_name, num_classes, pretrained='imagenet'):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    new_conv.weight.data[:,0:3,:] = model.conv1.weight.data.clone()\n",
    "    new_conv.weight.data[:,3:6,:] = model.conv1.weight.data.clone()\n",
    "    model.conv1 = new_conv\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Helper utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class RollingLoss:\n",
    "    def __init__(self, smooth=0.98):\n",
    "        self.smooth = smooth\n",
    "        self.prev = 0\n",
    "    def __call__(self, curr, batch_no):\n",
    "        a = self.smooth\n",
    "        avg_loss = a*self.prev + (1 - a)*curr\n",
    "        debias_loss = avg_loss/(1 - a**batch_no)\n",
    "        self.prev = avg_loss\n",
    "        return debias_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_layer(model, key):\n",
    "    \"\"\"Gets model layer using a key.\n",
    "    \n",
    "    The key could be hierarchical, like first.second.third where\n",
    "    each dot separates hierarchy level.\n",
    "    \"\"\"\n",
    "    parts = key.split('.')\n",
    "    block = model\n",
    "    for part in parts:\n",
    "        block = getattr(block, part)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze_layers(model, names):\n",
    "    for name in names:\n",
    "        layer = get_layer(model, name)\n",
    "        print(f'Unfreezing layer {name}')\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def train(epochs: int=1,\n",
    "          batch_size: int=800, \n",
    "          model_name: str='resnet34', \n",
    "          logdir: str='/tmp/loops/',\n",
    "          lrs: tuple=(1e-4, 1e-3, 5e-3),\n",
    "          eta_min: float=1e-6,\n",
    "          dev_id: int=1,\n",
    "          visdom_host: str='0.0.0.0',\n",
    "          visdom_port: int=9001):\n",
    "    \n",
    "    vis = Visdom(server=visdom_host, port=visdom_port,\n",
    "                 username=os.environ['VISDOM_USERNAME'],\n",
    "                 password=os.environ['VISDOM_PASSWORD'])\n",
    "    \n",
    "    experiment_id = f'{model_name}_e{epochs}_b{batch_size}'\n",
    "    device = torch.device(f'cuda:{dev_id}')\n",
    "    # dataset = create_data_loaders(*load_data(), batch_size=batch_size)\n",
    "    dataset = DataBunch().create(*load_data(), batch_size=batch_size)\n",
    "    model = get_model(model_name, NUM_CLASSES).to(device)\n",
    "    freeze_model(model)\n",
    "    unfreeze_layers(model, ['conv1', 'bn1', 'layer4', 'last_linear'])\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    conv, layer, head = lrs\n",
    "    opt = torch.optim.AdamW([\n",
    "        {'params': model.conv1.parameters(), 'lr': conv},\n",
    "        {'params': model.layer4.parameters(), 'lr': layer},\n",
    "        {'params': model.last_linear.parameters(), 'lr': head}\n",
    "    ], weight_decay=0.01)\n",
    "    logdir = os.path.join(logdir, experiment_id)\n",
    "    sched = CosineAnnealingWarmRestarts(\n",
    "        opt, T_0=len(dataset['train']), T_mult=2, eta_min=eta_min)\n",
    "    rolling_loss = RollingLoss()\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        trn_dl = dataset['train']\n",
    "        n = len(trn_dl)\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(total=n) as bar:\n",
    "            for i, batch in enumerate(trn_dl, 1):\n",
    "                iteration += 1\n",
    "                if i % 25 == 0:\n",
    "                    for j, g in enumerate(opt.param_groups):\n",
    "                        vis.line(X=[iteration], Y=[g['lr']], \n",
    "                                 win=f'metrics{j}', name=f'lr{j}', update='append')\n",
    "                bar.set_description(f'[epoch:{epoch}/{epochs}][{i}/{n}]')\n",
    "                opt.zero_grad()\n",
    "                x = batch['features'].to(device)\n",
    "                y = batch['targets'].to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, y)\n",
    "                loss.backward()\n",
    "                avg_loss = rolling_loss(loss.item(), iteration+1)\n",
    "                opt.step()\n",
    "                sched.step()\n",
    "                bar.set_postfix(avg_loss=f'{avg_loss:.3f}')\n",
    "                bar.update(1)\n",
    "                vis.line(X=[iteration], Y=[avg_loss],\n",
    "                         win='loss', name='avg_loss', update='append')\n",
    "\n",
    "        val_dl = dataset['valid']\n",
    "        n = len(val_dl)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            matches = []\n",
    "            with tqdm(total=n) as bar:\n",
    "                for batch in val_dl:\n",
    "                    x = batch['features'].to(device)\n",
    "                    y = batch['targets'].to(device)\n",
    "                    out = model(x)\n",
    "                    y_pred = out.softmax(dim=1).argmax(dim=1)\n",
    "                    matched = (y == y_pred).detach().cpu().numpy().tolist()\n",
    "                    matches.extend(matched)\n",
    "                    bar.update(1)\n",
    "            acc = np.mean(matches)\n",
    "            vis.line(X=[epoch], Y=[acc], win='acc', name='val_acc', update='append')\n",
    "            print(f'validation accuracy: {acc:2.2%}')\n",
    "            acc_str = str(int(round(acc * 10_000, 0)))\n",
    "            path = os.path.join(logdir, f'train.{epoch}.{acc_str}.pth')\n",
    "            torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    if not is_notebook():\n",
    "        ancli.make_cli(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train(model_name='resnet34', batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: report issue with one-hot smoothing AUC and accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2ab700352d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoints_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tmp/loops/resnet50_e200_b100'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(model_name, NUM_CLASSES)\n",
    "checkpoints = []\n",
    "checkpoints_path = '/tmp/loops/resnet50_e200_b100'\n",
    "for filename in os.listdir(checkpoints_path):\n",
    "    _, _, acc, _ = filename.split('.')\n",
    "    checkpoints.append((os.path.join(checkpoints_path, filename), int(acc)))\n",
    "checkpoints.sort(key=itemgetter(1))\n",
    "best, _ = checkpoints[-1]\n",
    "print('Best checkpoint:', best)\n",
    "model.load_state_dict(torch.load(best, map_location=lambda storage, loc: storage))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataBunch().create_test(load_data()[1], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "preds = []\n",
    "for batch in tqdm(test_dl):\n",
    "    out = model(batch['features'].to(device))\n",
    "    y = out.softmax(dim=1)\n",
    "    preds.extend(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(list_files('~/data/protein/tmp/test'))\n",
    "\n",
    "# odd\n",
    "site1 = []\n",
    "for filename, pred in list(zip(filenames, preds))[::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site1.append(pred)\n",
    "    \n",
    "# even\n",
    "site2 = []\n",
    "for filename, pred in list(zip(filenames, preds))[1::2]:\n",
    "    basename, _ = os.path.splitext(os.path.basename(filename))\n",
    "    sirna = int(basename.split('_')[-1])\n",
    "    if sirna != 0: \n",
    "        continue\n",
    "    site2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(site1)\n",
    "t2 = torch.tensor(site2)\n",
    "avg_pred = ((t1 + t2)/2).argmax(dim=1)\n",
    "print(avg_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/home/ck/data/protein/sample_submission.csv')\n",
    "sample['sirna'] = avg_pred.tolist()\n",
    "sample.to_csv('submit.csv', index=False)\n",
    "from IPython.display import FileLink\n",
    "FileLink('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# print('Saving the trained model')\n",
    "# basedir = os.path.expanduser('~/data/protein/tmp/models')\n",
    "# os.makedirs(basedir)\n",
    "# torch.save(resnet, os.path.join(basedir, 'resnet50_simple.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
