{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from data_bunch import rio\n",
    "from basedir import NUM_CLASSES\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from functools import partial\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import os\n",
    "\n",
    "from catalyst.utils import get_one_hot\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def six(rec):\n",
    "    return np.stack([imread(filename) for _, filename in rec['images']])\n",
    "\n",
    "def rgb(img):\n",
    "    if img.shape[0] == 6:\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    return rio.convert_tensor_to_rgb(img)\n",
    "\n",
    "def show_1(img, ax=None):\n",
    "    if img.shape[0] == 6:\n",
    "        img = rgb(img)\n",
    "    if img.shape[0] == 3:\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    elif img.shape[-1] != 3:\n",
    "        raise ValueError(f'wrong image shape: {img.shape}')\n",
    "    if ax is not None:\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    \n",
    "def show(img, *imgs, titles=None, ncols=4):\n",
    "    from itertools import zip_longest\n",
    "    imgs = [img] + list(imgs)\n",
    "    titles = titles or []\n",
    "    nrows = int(np.ceil(len(imgs) / ncols))\n",
    "    sz = max(nrows, ncols)*2\n",
    "    f, axes = plt.subplots(nrows, ncols, figsize=(sz, sz))\n",
    "    for ax, img, t in zip_longest(axes.flat, imgs, titles):\n",
    "        if img is not None:\n",
    "            show_1(img, ax)\n",
    "        ax.set_title(t)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "    f.subplots_adjust(wspace=0, hspace=0.5)\n",
    "    return f\n",
    "\n",
    "def sample(records, count=1):\n",
    "    n = len(records)\n",
    "    idx = np.random.choice(n, count)\n",
    "    return [records[i] for i in idx]\n",
    "\n",
    "def visualize(records, n=25):\n",
    "    samples = sample(records, n)\n",
    "    titles = [\"{}\\n{}\".format(s['cell_type'], s['well_type']) for s in samples]\n",
    "    show(*map(six, samples), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(folder):\n",
    "    dirname = os.path.expanduser(folder)\n",
    "    return [os.path.join(dirname, x) for x in os.listdir(dirname)]\n",
    "\n",
    "def load_data(filenames=None):\n",
    "    if filenames is None:\n",
    "        filenames = [f'{fn}.json' for fn in ('train', 'test')]\n",
    "    content = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            content.append(json.load(f))\n",
    "    return content\n",
    "\n",
    "class RxRxDataset(Dataset):\n",
    "    def __init__(self, items, onehot=True, label_smoothing=None,\n",
    "                 features_key='images', targets_key='sirna',\n",
    "                 channels_mode='six', drop_meta=True, \n",
    "                 num_classes=NUM_CLASSES, open_fn=PIL.Image.open, tr=None):\n",
    "        \n",
    "        assert channels_mode in ('six', 'rgb')\n",
    "        super().__init__()      \n",
    "        self.items = items\n",
    "        self.onehot = onehot\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.features_key = features_key\n",
    "        self.targets_key = targets_key\n",
    "        self.channels_mode = channels_mode\n",
    "        self.drop_meta = drop_meta\n",
    "        self.num_classes = num_classes\n",
    "        self.open_fn = open_fn\n",
    "        self.tr = tr\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.items[index].copy()\n",
    "        bunch = sorted(item.pop(self.features_key), key=itemgetter(0))\n",
    "        channels = OrderedDict()\n",
    "        if self.channels_mode == 'six':\n",
    "            for i, filename in bunch:\n",
    "                channels[f'chan_{i}'] = np.array(self.open_fn(filename))\n",
    "        elif self.channels_mode == 'rgb':\n",
    "            img = np.stack([self.open_fn(filename) for filename in bunch])\n",
    "            img = rio.convert_tensor_to_rgb(img)\n",
    "            for i in range(3):\n",
    "                channes[f'chan_{i}'] = img[i,:,:]\n",
    "        y = item[self.targets_key]\n",
    "        if self.drop_meta:\n",
    "            sample = item\n",
    "            sample['features'] = channels\n",
    "            sample['targets'] = y\n",
    "        else:\n",
    "            sample = dict(features=channels, targets=y)\n",
    "        if self.onehot:\n",
    "            y_enc = get_one_hot(\n",
    "                y, smoothing=self.label_smoothing,\n",
    "                num_classes=self.num_classes)\n",
    "            sample['targets_one_hot'] = y_enc\n",
    "        return sample\n",
    "    \n",
    "    def join_channels(self, x):\n",
    "        return np.stack([channel for _, channel in x['features'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_rec, _ = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(trn_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxrx_ds = RxRxDataset(trn_rec, onehot=True)\n",
    "x = rxrx_ds[9090]\n",
    "img = rxrx_ds.join_channels(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose(\n",
    "    additional_targets={f'image{i}': 'image' for i in range(5)},\n",
    "    transforms=[\n",
    "        T.VerticalFlip(p=0.5),\n",
    "        T.HorizontalFlip(p=0.5),\n",
    "        T.Rotate(p=0.25)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, tr):\n",
    "    main, *rest = list(x['features'].values())\n",
    "    aug_input = dict(image=main)\n",
    "    aug_input.update({f'image{i}': image for i, image in enumerate(rest)})\n",
    "    augmented = tr(**aug_input)\n",
    "    unpacked = [augmented['image']] + [augmented[f'image{i}'] for i in range(5)]\n",
    "    sample = np.stack(unpacked)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmented(Dataset):\n",
    "    def __init__(self, ds, tr):\n",
    "        self.ds = ds\n",
    "        self.tr = tr\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __getitem__(self, index):\n",
    "        return augment(self.ds[index], self.tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'images': [[1, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w1.png'],\n",
       "   [2, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w2.png'],\n",
       "   [3, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w3.png'],\n",
       "   [4, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w4.png'],\n",
       "   [5, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w5.png'],\n",
       "   [6, '/home/ck/data/protein/train/HEPG2-01/Plate1/B02_s1_w6.png']],\n",
       "  'sirna': 1138,\n",
       "  'site': 1,\n",
       "  'cell_type': 'HEPG2',\n",
       "  'experiment': 'HEPG2-01',\n",
       "  'well_type': 'negative_control',\n",
       "  'plate': 1}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_rec[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = defaultdict(list)\n",
    "for record in trn_rec:\n",
    "    cell_types[record['cell_type']].append(record)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct, records in cell_types.items():\n",
    "    [r for r in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ds = Augmented(rxrx_ds, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import pretrainedmodels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "from catalyst.contrib.modules import GlobalConcatPool2d\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from catalyst.dl.core import Callback\n",
    "from visdom import Visdom\n",
    "from pdb import set_trace\n",
    "\n",
    "\n",
    "class VisdomCallback(Callback):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 username='username', password='password', \n",
    "                 host='0.0.0.0', port=9090, use_env_creds=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            username (str): Visdom server username.\n",
    "            password (str): Visdom server password.\n",
    "            host (str): Visdom server address.\n",
    "            port (int): Visdom server port.\n",
    "            use_env_creds (bool): If True, then ignore credentials\n",
    "                passed as __init__ parameters and use Visdom \n",
    "                environment variables instead.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        if use_env_creds:\n",
    "            username = os.environ['VISDOM_USERNAME']\n",
    "            password = os.environ['VISDOM_PASSWORD']\n",
    "            \n",
    "        self.vis = Visdom(\n",
    "            username=username, password=password,\n",
    "            server=host, port=port)        \n",
    "\n",
    "        \n",
    "class BatchMetricsPlotCallback(VisdomCallback):\n",
    "\n",
    "    def on_batch_end(self, state):\n",
    "        for k, v in state.metrics.batch_values.items():\n",
    "            self.vis.line(X=[state.step], Y=[v], win=k, name=k, \n",
    "                          update='append', opts=dict(title=k))\n",
    "            \n",
    "            \n",
    "class EpochMetricsPlotCallback(VisdomCallback):\n",
    "    \n",
    "    def on_epoch_end(self, state):\n",
    "        for k, v in state.metrics.batch_values.items():\n",
    "            self.vis.line(X=[state.step], Y=[v], win=k, name=k,\n",
    "                          update='append', opts=dict(title=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_model():\n",
    "    model = pretrainedmodels.resnet50()\n",
    "    model.avgpool = GlobalConcatPool2d()\n",
    "    model.last_linear = nn.Sequential(\n",
    "        nn.Linear(4096, 2048),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 4)\n",
    "    )\n",
    "    conv1 = model.conv1\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    new_conv.weight.data[:,0:3,:] = conv1.weight.data.clone()\n",
    "    new_conv.weight.data[:,3:6,:] = conv1.weight.data.clone()\n",
    "    model.conv1 = new_conv\n",
    "    del conv1\n",
    "    return model\n",
    "    \n",
    "def freeze_all(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def unfreeze_head(model):\n",
    "    for param in model.last_linear.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "epochs = 3\n",
    "model = build_model()\n",
    "freeze_all(model)\n",
    "unfreeze_head(model)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "sched = CosineAnnealingWarmRestarts(opt, T_0=len(aug_ds), T_mult=2, eta_min=1e-6)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "runner = SupervisedRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = dict(train=aug_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 23:50:23.888358 139970826073920 __init__.py:505] Setting up a new session...\n",
      "W0906 23:50:23.996115 139970826073920 __init__.py:505] Setting up a new session...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "'valid' should be in provided loaders: ['train']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5ed1268f00d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mEpochMetricsPlotCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_env_creds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ],\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/runner/supervised.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, loaders, logdir, callbacks, scheduler, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, check)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mdistributed_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         )\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     def infer(\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment, check)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}_post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}_post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/state.py\u001b[0m in \u001b[0;36mon_exception_post\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_exception_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/callbacks/logging.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_reraise_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment, check)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/open_source/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0;34mf\"'{self.state.valid_loader}' \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0;34mf\"should be in provided loaders: {list(loaders.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 'valid' should be in provided loaders: ['train']"
     ]
    }
   ],
   "source": [
    "#export\n",
    "runner.train(\n",
    "    model=model,\n",
    "    num_epochs=epochs,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=opt,\n",
    "    scheduler=sched,\n",
    "    logdir='/tmp/cells_split/',\n",
    "    loaders=loaders,\n",
    "    callbacks=[\n",
    "        AccuracyCallback(num_classes=4),\n",
    "        BatchMetricsPlotCallback(use_env_creds=True),\n",
    "        EpochMetricsPlotCallback(use_env_creds=True)\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
