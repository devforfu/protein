{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupytools.syspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from basedir import ROOT, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupytools.syspath.add('/home/ck/code/tasks/protein_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_csv = pd.read_csv(ROOT/'train.csv')\n",
    "tst_csv = pd.read_csv(ROOT/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_groups = np.zeros((1108,4), int)\n",
    "for sirna in range(1108):\n",
    "    grp = trn_csv.loc[trn_csv.sirna==sirna,:].plate.value_counts().index.values\n",
    "    assert len(grp) == 3\n",
    "    plate_groups[sirna,0:3] = grp\n",
    "    plate_groups[sirna,3] = 10 - grp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('densenet121_two_way_512.csv')\n",
    "sub = pd.read_csv('densenet121_long_training_e29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_exp = tst_csv.experiment.unique()\n",
    "\n",
    "group_plate_probs = np.zeros((len(all_test_exp),4))\n",
    "for idx in range(len(all_test_exp)):\n",
    "    preds = sub.loc[tst_csv.experiment == all_test_exp[idx],'sirna'].values\n",
    "    pp_mult = np.zeros((len(preds),1108))\n",
    "    pp_mult[range(len(preds)),preds] = 1\n",
    "    \n",
    "    sub_test = tst_csv.loc[tst_csv.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    \n",
    "    for j in range(4):\n",
    "        mask = np.repeat(plate_groups[np.newaxis, :, j], len(pp_mult), axis=0) == \\\n",
    "               np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "        \n",
    "        group_plate_probs[idx,j] = np.array(pp_mult)[mask].sum()/len(pp_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HEPG2-08</th>\n",
       "      <td>0.109304</td>\n",
       "      <td>0.112918</td>\n",
       "      <td>0.122855</td>\n",
       "      <td>0.654923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-09</th>\n",
       "      <td>0.147112</td>\n",
       "      <td>0.481949</td>\n",
       "      <td>0.199458</td>\n",
       "      <td>0.171480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-10</th>\n",
       "      <td>0.711191</td>\n",
       "      <td>0.094765</td>\n",
       "      <td>0.093863</td>\n",
       "      <td>0.100181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-11</th>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.072333</td>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.082278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-17</th>\n",
       "      <td>0.791516</td>\n",
       "      <td>0.064079</td>\n",
       "      <td>0.074910</td>\n",
       "      <td>0.069495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-18</th>\n",
       "      <td>0.620596</td>\n",
       "      <td>0.144535</td>\n",
       "      <td>0.109304</td>\n",
       "      <td>0.125565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-19</th>\n",
       "      <td>0.089350</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.725632</td>\n",
       "      <td>0.098375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-20</th>\n",
       "      <td>0.037004</td>\n",
       "      <td>0.035199</td>\n",
       "      <td>0.882671</td>\n",
       "      <td>0.045126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-21</th>\n",
       "      <td>0.085740</td>\n",
       "      <td>0.092960</td>\n",
       "      <td>0.110108</td>\n",
       "      <td>0.711191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-22</th>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>0.075812</td>\n",
       "      <td>0.056859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-23</th>\n",
       "      <td>0.806187</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.057325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-24</th>\n",
       "      <td>0.069091</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>0.804545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPE-08</th>\n",
       "      <td>0.128159</td>\n",
       "      <td>0.613718</td>\n",
       "      <td>0.123646</td>\n",
       "      <td>0.134477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPE-09</th>\n",
       "      <td>0.691960</td>\n",
       "      <td>0.110208</td>\n",
       "      <td>0.096658</td>\n",
       "      <td>0.101174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPE-10</th>\n",
       "      <td>0.689531</td>\n",
       "      <td>0.106498</td>\n",
       "      <td>0.091155</td>\n",
       "      <td>0.112816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPE-11</th>\n",
       "      <td>0.699269</td>\n",
       "      <td>0.076782</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.112431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U2OS-04</th>\n",
       "      <td>0.231949</td>\n",
       "      <td>0.229242</td>\n",
       "      <td>0.296029</td>\n",
       "      <td>0.242780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U2OS-05</th>\n",
       "      <td>0.175023</td>\n",
       "      <td>0.198724</td>\n",
       "      <td>0.176846</td>\n",
       "      <td>0.449407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3\n",
       "HEPG2-08  0.109304  0.112918  0.122855  0.654923\n",
       "HEPG2-09  0.147112  0.481949  0.199458  0.171480\n",
       "HEPG2-10  0.711191  0.094765  0.093863  0.100181\n",
       "HEPG2-11  0.765823  0.072333  0.079566  0.082278\n",
       "HUVEC-17  0.791516  0.064079  0.074910  0.069495\n",
       "HUVEC-18  0.620596  0.144535  0.109304  0.125565\n",
       "HUVEC-19  0.089350  0.086643  0.725632  0.098375\n",
       "HUVEC-20  0.037004  0.035199  0.882671  0.045126\n",
       "HUVEC-21  0.085740  0.092960  0.110108  0.711191\n",
       "HUVEC-22  0.812274  0.055054  0.075812  0.056859\n",
       "HUVEC-23  0.806187  0.063694  0.072793  0.057325\n",
       "HUVEC-24  0.069091  0.068182  0.058182  0.804545\n",
       "RPE-08    0.128159  0.613718  0.123646  0.134477\n",
       "RPE-09    0.691960  0.110208  0.096658  0.101174\n",
       "RPE-10    0.689531  0.106498  0.091155  0.112816\n",
       "RPE-11    0.699269  0.076782  0.111517  0.112431\n",
       "U2OS-04   0.231949  0.229242  0.296029  0.242780\n",
       "U2OS-05   0.175023  0.198724  0.176846  0.449407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(group_plate_probs, index=all_test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference\n",
    "# exp_to_group = group_plate_probs.argmax(1)\n",
    "# print(exp_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 0 0 0 2 2 3 0 0 3 1 0 0 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "exp_to_group = group_plate_probs.argmax(1)\n",
    "print(exp_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation import JoinChannels, SwapChannels, Resize, ToFloat, Rescale\n",
    "from augmentation import VerticalFlip, HorizontalFlip, PixelStatsNorm, composer\n",
    "from augmentation import AugmentedImages, bernoulli\n",
    "from imageio import imread\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "default_open_fn = imread  # PIL.Image.open\n",
    "\n",
    "class RxRxImages(Dataset):\n",
    "    def __init__(self, meta_df, img_dir, site=1, channels=(1, 2, 3, 4, 5, 6), \n",
    "                 open_image=default_open_fn, n_classes=NUM_CLASSES, train=True):\n",
    "        \n",
    "        self.records = meta_df.to_records(index=False)\n",
    "        self.img_dir = img_dir\n",
    "        self.site = site\n",
    "        self.channels = channels\n",
    "        self.n = len(self.records)\n",
    "        self.open_image = open_image\n",
    "        self.n_classes = n_classes\n",
    "        self.train = train\n",
    "        \n",
    "    def _get_image_path(self, index, channel):\n",
    "        r = self.records[index]\n",
    "        exp, plate, well = r.experiment, r.plate, r.well\n",
    "        subdir = 'train' if self.train else 'test'\n",
    "        path = f'{self.img_dir}/{subdir}/{exp}/Plate{plate}/{well}_s{self.site}_w{channel}.png'\n",
    "        return path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        paths = [self._get_image_path(index, ch) for ch in self.channels]\n",
    "        images = [self.open_image(p) for p in paths]\n",
    "\n",
    "        try:\n",
    "            img = np.stack(images)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            print(f'Warning: cannot concatenate images! {e.__class__.__name__}: {e}')\n",
    "            for filename, image in zip(paths, images):\n",
    "                print(f'\\tpath={filename}, size={image.size}')\n",
    "            index = (index + 1) % len(self)\n",
    "            print(f'Skipping instance {index} and trying another one...')\n",
    "            return self[index]\n",
    "        finally:\n",
    "            for image in images:\n",
    "                if hasattr(image, 'close'):\n",
    "                    image.close()\n",
    "            \n",
    "        img = img.astype(np.float32)\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        r = self.records[index]\n",
    "        if self.train:\n",
    "            sirna = r.sirna\n",
    "            target = int(sirna)\n",
    "            onehot = get_one_hot(target, num_classes=self.n_classes)\n",
    "            return {'features': img, 'targets': target, \n",
    "                    'targets_one_hot': onehot, 'id_code': r.id_code,\n",
    "                    'site': self.site}\n",
    "        else:\n",
    "            id_code = r.id_code\n",
    "            return {'features': img, 'id_code': id_code, 'site': self.site}\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.n\n",
    "    \n",
    "class TwoSiteImages(Dataset):\n",
    "    def __init__(self, ds1, ds2, swap=0.0):\n",
    "        assert len(ds1) == len(ds2)\n",
    "        self.ds1, self.ds2 = ds1, ds2\n",
    "        self.swap = swap\n",
    "        self.size = len(ds1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        s1, s2 = self.ds1[index], self.ds2[index]\n",
    "        if self.swap and bernoulli(self.swap) == 1:\n",
    "            s1, s2 = s2, s1\n",
    "        return {'site1': s1, 'site2': s2}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.modules import GlobalConcatPool2d\n",
    "import pretrainedmodels\n",
    "import torch.nn as nn\n",
    "\n",
    "def densenet(name='densenet121', n_classes=NUM_CLASSES):\n",
    "    model_fn = pretrainedmodels.__dict__[name]\n",
    "    model = model_fn(num_classes=1000, pretrained='imagenet')\n",
    "    new_conv = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "    conv0 = model.features.conv0.weight\n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:, :] = torch.stack([torch.mean(conv0, 1)]*6, dim=1)\n",
    "    model.features.conv0 = new_conv\n",
    "    return model\n",
    "\n",
    "class DenseNet_TwoSites(nn.Module):\n",
    "    def __init__(self, name, n_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        \n",
    "        base = densenet(name=name, n_classes=n_classes)\n",
    "        feat_dim = base.last_linear.in_features\n",
    "        \n",
    "        self.base = base \n",
    "        self.pool = GlobalConcatPool2d()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim * 2, feat_dim * 2),\n",
    "            nn.BatchNorm1d(feat_dim * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(feat_dim * 2, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, s1, s2):\n",
    "        f1 = self.base.features(s1)\n",
    "        f2 = self.base.features(s2)\n",
    "        f_merged = self.pool(f1 + f2)\n",
    "        out = self.head(f_merged.squeeze())\n",
    "        return out\n",
    "    \n",
    "def freeze_all(model):\n",
    "    for name, child in model.named_children():\n",
    "        print('Freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "def unfreeze_all(model):\n",
    "    for name, child in model.named_children():\n",
    "        print('Un-freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "def unfreeze_layers(model, names):\n",
    "    for name, child in model.named_children():\n",
    "        if name not in names:\n",
    "            continue\n",
    "        print('Un-freezing layer:', name)\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import build_stats_index\n",
    "\n",
    "sz = 512\n",
    "\n",
    "tst_df = pd.read_csv(ROOT/'test.csv')\n",
    "\n",
    "stats = build_stats_index(ROOT/'pixel_stats.csv')\n",
    "\n",
    "tst_ds = TwoSiteImages(\n",
    "    ds1=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=1, train=False), tr=composer([\n",
    "        PixelStatsNorm(stats, channels_first=False)\n",
    "    ], resize=sz, rescale=False)),\n",
    "    ds2=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=2, train=False), tr=composer([\n",
    "        PixelStatsNorm(stats, channels_first=False)\n",
    "    ], resize=sz, rescale=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer: base\n",
      "Freezing layer: pool\n",
      "Freezing layer: head\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1')\n",
    "model = DenseNet_TwoSites('densenet121')\n",
    "freeze_all(model)\n",
    "\n",
    "model.to(device)\n",
    "# state = torch.load('densenet121_15_cw/train.14.pth', map_location=lambda loc, storage: loc)\n",
    "# model.load_state_dict(state)\n",
    "state = torch.load('densenet121_long_training/train.29.pth', \n",
    "                   map_location=lambda loc, storage: loc)\n",
    "model.load_state_dict(state['model'])\n",
    "_ = model.eval()\n",
    "\n",
    "tst_df = pd.read_csv(ROOT/'test.csv')\n",
    "\n",
    "stats = build_stats_index(ROOT/'pixel_stats.csv')\n",
    "\n",
    "tst_ds = TwoSiteImages(\n",
    "    ds1=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=1, train=False), tr=composer([\n",
    "        PixelStatsNorm(stats, channels_first=False)\n",
    "    ], resize=sz, rescale=False)),\n",
    "    ds2=AugmentedImages(ds=RxRxImages(tst_df, ROOT, site=2, train=False), tr=composer([\n",
    "        PixelStatsNorm(stats, channels_first=False)\n",
    "    ], resize=sz, rescale=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loader(ds, bs, drop_last=False, shuffle=True, num_workers=12):\n",
    "    return DataLoader(ds, batch_size=bs, drop_last=drop_last, \n",
    "                      shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad629dad19fa437dada5e5c6a06ef8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=311), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_dl = new_loader(tst_ds, bs=64, shuffle=False)\n",
    "    preds = []\n",
    "    for batch in tqdm(test_dl):\n",
    "        s1 = batch['site1']['features']\n",
    "        s2 = batch['site2']['features']\n",
    "        out = model(s1.to(device), s2.to(device))\n",
    "        probs = out.softmax(dim=-1).cpu().numpy()\n",
    "        preds.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.row_stack(preds).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19897, 1108)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_plate_group(pp_mult, idx):\n",
    "    sub_test = tst_csv.loc[tst_csv.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    mask = np.repeat(plate_groups[np.newaxis, :, exp_to_group[idx]], len(pp_mult), axis=0) != \\\n",
    "           np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "    pp_mult[mask] = 0\n",
    "    return pp_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.set_index('id_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(all_test_exp)):\n",
    "    indexes = tst_csv.experiment == all_test_exp[idx]\n",
    "    preds = stacked[indexes, :].copy()\n",
    "    preds = select_plate_group(preds, idx)\n",
    "    sub.loc[tst_csv.id_code[indexes], 'sirna'] = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46027039252148566"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub.sirna == pd.read_csv('densenet121_two_way_512.csv').sirna).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='densenet121_long_training_e29_leak.csv' target='_blank'>densenet121_long_training_e29_leak.csv</a><br>"
      ],
      "text/plain": [
       "/home/ck/code/tasks/protein/densenet121_long_training_e29_leak.csv"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "sub.to_csv('densenet121_long_training_e29_leak.csv', index=False, columns=['id_code', 'sirna'])\n",
    "FileLink('densenet121_long_training_e29_leak.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
